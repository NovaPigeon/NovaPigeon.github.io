<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.2.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="google-site-verification" content="deuDv-EAk16ZxOmNULcCaGJT7A3rePc-Xmn__lwF9kc">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha256-XOqroi11tY4EFQMR9ZYwZWKj5ZXiftSx36RRuC3anlA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"novapigeon.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.20.0","exturl":true,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"mac"},"fold":{"enable":true,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":true,"comments":{"style":"tabs","active":"giscus","storage":true,"lazyload":true,"nav":null,"activeClass":"giscus"},"stickytabs":true,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":-1,"unescape":true,"preload":true}}</script><script src="/js/config.js"></script>

    <meta name="description" content="Efficient and Affordable Post-Training Quantization for Large-Scale Transformers.">
<meta property="og:type" content="article">
<meta property="og:title" content="ZeroQuant">
<meta property="og:url" content="https://novapigeon.github.io/2024/05/15/ZeroQuant/index.html">
<meta property="og:site_name" content="NovaPigeon&#39;s Blog">
<meta property="og:description" content="Efficient and Affordable Post-Training Quantization for Large-Scale Transformers.">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://novapigeon.github.io/2024/05/15/ZeroQuant/f2.png">
<meta property="og:image" content="https://novapigeon.github.io/2024/05/15/ZeroQuant/f1.png">
<meta property="og:image" content="https://novapigeon.github.io/2024/05/15/ZeroQuant/f4.png">
<meta property="og:image" content="https://novapigeon.github.io/2024/05/15/ZeroQuant/f3.png">
<meta property="article:published_time" content="2024-05-15T10:12:30.000Z">
<meta property="article:modified_time" content="2024-05-20T21:00:19.763Z">
<meta property="article:author" content="NovaPigeon">
<meta property="article:tag" content="MLSys">
<meta property="article:tag" content="LLM">
<meta property="article:tag" content="LLM Compression">
<meta property="article:tag" content="Quantization">
<meta property="article:tag" content="PTQ">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://novapigeon.github.io/2024/05/15/ZeroQuant/f2.png">


<link rel="canonical" href="https://novapigeon.github.io/2024/05/15/ZeroQuant/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://novapigeon.github.io/2024/05/15/ZeroQuant/","path":"2024/05/15/ZeroQuant/","title":"ZeroQuant"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>ZeroQuant | NovaPigeon's Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">NovaPigeon's Blog</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">代大匠斫者</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#background-knowledge"><span class="nav-number">1.</span> <span class="nav-text">Background Knowledge</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#quantization"><span class="nav-number">1.1.</span> <span class="nav-text">Quantization:</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#dequantization"><span class="nav-number">1.2.</span> <span class="nav-text">Dequantization:</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ptqpost-training-quatization"><span class="nav-number">1.3.</span> <span class="nav-text">PTQ(Post-training-quatization)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#qatquantization-aware-training"><span class="nav-number">1.4.</span> <span class="nav-text">QAT(Quantization-aware-training)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#challenge-and-motivation"><span class="nav-number">2.</span> <span class="nav-text">Challenge and Motivation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#methodology"><span class="nav-number">3.</span> <span class="nav-text">Methodology</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#group-wise-quantization-for-weights"><span class="nav-number">3.1.</span> <span class="nav-text">Group-wise Quantization for
Weights：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#token-wise-quantization-for-activations"><span class="nav-number">3.2.</span> <span class="nav-text">Token-wise Quantization
for Activations</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#quantization-optimized-transformer-kernels"><span class="nav-number">3.3.</span> <span class="nav-text">Quantization-Optimized
Transformer Kernels</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#layer-by-layer-knowledge-distillation-lkd"><span class="nav-number">3.4.</span> <span class="nav-text">Layer-by-layer
knowledge distillation (LKD)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#results"><span class="nav-number">4.</span> <span class="nav-text">Results</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#reference"><span class="nav-number">5.</span> <span class="nav-text">Reference</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="NovaPigeon"
      src="/images/avator.jpg">
  <p class="site-author-name" itemprop="name">NovaPigeon</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">7</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://novapigeon.github.io/2024/05/15/ZeroQuant/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avator.jpg">
      <meta itemprop="name" content="NovaPigeon">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="NovaPigeon's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="ZeroQuant | NovaPigeon's Blog">
      <meta itemprop="description" content="Efficient and Affordable Post-Training Quantization for Large-Scale Transformers.">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          ZeroQuant
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-05-15 18:12:30" itemprop="dateCreated datePublished" datetime="2024-05-15T18:12:30+08:00">2024-05-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-05-21 05:00:19" itemprop="dateModified" datetime="2024-05-21T05:00:19+08:00">2024-05-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Paper-Reading/" itemprop="url" rel="index"><span itemprop="name">Paper Reading</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
</div>

            <div class="post-description">Efficient and Affordable Post-Training Quantization for Large-Scale Transformers.</div>
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h2 id="background-knowledge">Background Knowledge</h2>
<h3 id="quantization">Quantization:</h3>
<p>Idea
很简单，就是把模型的参数和运算从浮点数（FP32）映射到较低的精度，比如
INT8。这样做有两点好处。</p>
<ol type="1">
<li>减小了模型的大小，降低了内存开销。</li>
<li>一般来讲 CPU/GPU
做整形运算的速度都比浮点运算快，可以提升推理速度。</li>
</ol>
<p>映射需要在降低模型精度的同时，维持量化之后参数分布与量化之前分布的同构性。其实线性映射就能做的很好了。</p>
<p>如下式所示，将原始值 <span class="math inline">\(r\)</span> 映射到
<span class="math inline">\([q_{min},q_{max}]\)</span></p>
<p><span
class="math display">\[S=\frac{r_{max}-r_{min}}{q_{max}-q_{min}}\]</span>
<span class="math display">\[Z=-\frac{r_{min}}{S}+q_{min}\]</span> <span
class="math display">\[q=\lfloor \frac{r}{S}+Z \rfloor\]</span></p>
<p>其中，<span class="math inline">\(S\)</span> 用于缩放，<span
class="math inline">\(Z\)</span> 用于确定零点。我们需要做的就是确定
<span class="math inline">\(S,Z\)</span>。</p>
<p>可以看出来，在量化的计算中 <span
class="math inline">\(r_{range}=r_{max}-r_{min}\)</span>
是至关重要的，量化的结果也是 range 敏感的。
在下面论文的讲解中我们也会用到这点。</p>
<p>模型量化的对象主要有 Weight, Activation, KV cache,
Gradients。(量化的不仅是参数，还有运算)</p>
<h3 id="dequantization">Dequantization:</h3>
<p>模型中一些算子支持低精度表示，那么很好，直接算就行了。</p>
<p>但还有一些算子需要高精度的输入输出（低精度导致很大的误差），就需要将
INT8 反量化为 FP32 再喂给算子计算。</p>
<p><span class="math display">\[r=S(q-Z)\]</span></p>
<p>这会引入误差。</p>
<h3
id="ptqpost-training-quatization">PTQ(Post-training-quatization)</h3>
<p>PTQ，即训练后量化，在模型完成训练之后对模型进行量化。</p>
<p>之前说过，量化需要确定 <span class="math inline">\(S,Z\)</span>，而
<span class="math inline">\(S,Z\)</span> 又由 <span
class="math inline">\(r_{max},r_{min}\)</span> 确定，PTQ
通过选取少量校准数据估算出参数分布，来得到 <span
class="math inline">\(r_{max},r_{min}\)</span>。</p>
<p>以 FP32-&gt;INT8 的 PTQ 为例： 1. 训练出 FP32 的 baseline 模型。 2.
Calibration：使用少量数据估算得到网络各层 weight/activation 的分布，得到
<span class="math inline">\(r_{max},r_{min}\)</span> 3. 算出各层的 <span
class="math inline">\(S,Z\)</span>。 4. 用 <span
class="math inline">\(S,Z\)</span>，将 FP32 的 baseline 量化得到
INT8。</p>
<p>PTQ 运算速度较快，但会损失一定精度。</p>
<h3
id="qatquantization-aware-training">QAT(Quantization-aware-training)</h3>
<p>QAT，即量化感知训练。PTQ 中训练与量化是分开的，但是 QAT
通过在训练时加入伪量化算子，模拟量化带来的误差。</p>
<p>以 FP32-&gt;INT8 的 QAT 为例： 1. 训练出 FP32 的 baseline 模型。 2.
在 baseline model 中加入插入伪量化算子，在数据集上 finetune 得到的 QAT
model。 3. 伪量化算子模拟推理时的量化，并保存 finetune
时得到的量化参数。 4. finetune 完成后，使用量化参数将 QAT model 量化为
INT8 model。</p>
<p>伪量化算子就是量化与反量化算子的结合，模拟 round
带来的误差，定义如下，</p>
<p><span class="math display">\[clamp(r;a,b)=min(max(x,a),b)\]</span>
<span class="math display">\[s(a,b,n)=\frac{b-a}{n-1}\]</span> <span
class="math display">\[q(r;a,b,n)=\lfloor\frac{clamp(r;a,b)-a}{s(a,b,n)}\rfloor
s(a,b,n)+a\]</span></p>
<h2 id="challenge-and-motivation">Challenge and Motivation</h2>
<p>随着大模型的规模急剧增加，大模型的推理面对着两个问题，极高 GPU
内存占用和计算开销。</p>
<p>而解决这一问题的办法之一就是量化。其一可以降低模型的内存占用，其二可以提升模型的运算性能。</p>
<p>然而，为了弥补量化导致的精度损失，通常需要使用 QAT 技术，retrain
模型。这会带来几个问题：</p>
<ol type="1">
<li>训练用的数据往往不是公开的。</li>
<li>重新训练模型所需要很多计算资源。</li>
<li>耗时很久。</li>
</ol>
<p>PTQ 技术就能解决这些问题，因为 PTQ</p>
<ol type="1">
<li>不需要训练数据。</li>
<li>极少的计算资源。</li>
<li>几乎不需要重新训练。</li>
</ol>
<p>最近也有一些关于 PTQ 的量化工作，但是这些工作</p>
<ol type="1">
<li>只关注小规模的 CV 问题。</li>
<li>只局限于高精度量化（INT8/FP16），且只支持 BERT 模型。</li>
<li>不关注量化和反量化开销。（这是性能的重要组成部分）</li>
<li>对于极端量化（如
INT4）或更高的精度，通常使用知识蒸馏，导致额外的开销。</li>
</ol>
<p>我们想要使用 PTQ 技术来解决上述问题，但是直接使用 PTQ
技术是不可行的，会导致 accuracy 的下降。</p>
<p>如图所示，图中 WXAY 代表 Weight 和 Activation 的量化精度。</p>
<img src="/2024/05/15/ZeroQuant/f2.png" class="">
<p>可以看到，INT8 激活量化带来了主要的精度损失，而 weight
量化会导致生成式任务的性能变差。（但 zero-shot 对此不敏感）</p>
<p>为什么 INT8 量化会导致精度损失呢？</p>
<ol type="1">
<li>激活层的 range 是动态变化的，左图显示了对不同 token
而言，激活层输出的 range 有非常大的差异。譬如说 layer11，最小的 range 为
8，最大的 range 为 35。如果对所有 token 使用相同的量化范围的话，range
较小的 token 就会损失很多精度。</li>
<li>Weight 中不同行的 range 差距极大。如右图所示，不同行的 range
之间最多有十倍的差距，但是 PTQ 对整个 Weight Matrix
是一起量化的，取的是整个 Weight 的范围。导致 PTQ 的性能较差。如果使用
INT4 量化（总共 16 个数），那对于 range 较小的行，可能只有 2-3
个数的表示范围。</li>
</ol>
<img src="/2024/05/15/ZeroQuant/f1.png" class="">
<h2 id="methodology">Methodology</h2>
<p>为此，Paper 提出了以下几个技术：</p>
<h3 id="group-wise-quantization-for-weights">Group-wise Quantization for
Weights：</h3>
<ol type="1">
<li>将权重矩阵划分为多个组，每个组分别量化。</li>
<li>针对 GPU 做了优化，降低了推理延迟。</li>
</ol>
<img src="/2024/05/15/ZeroQuant/f4.png" class="">
<h3 id="token-wise-quantization-for-activations">Token-wise Quantization
for Activations</h3>
<ol type="1">
<li>PTQ
一般是静态量化激活的。譬如说离线校准时计算出激活层范围。但是，对于大模型而言，不同
token 的激活范围差异极大，统一静态的量化会导致极大的精度损失。</li>
<li>自然的想法是使用更细粒度的量化策略。这篇 paper 提出了逐 token
量化的技术，动态计算每个 token 的激活值范围，再做量化。</li>
<li>消除了激活范围校准的开销。</li>
<li>但是，逐 token 量化会引入显著的量化和反量化成本，为此，paper
设计了一个高度优化的推理后端。</li>
</ol>
<h3
id="quantization-optimized-transformer-kernels">Quantization-Optimized
Transformer Kernels</h3>
<ol type="1">
<li>在推理过程中，batch-size 较小，因此推理的延迟主要是 device 和 host
之间的内存搬运导致的。</li>
<li>量化本身降低了模型的大小，减少了加载的数据量。但是，量化和反量化运算又导致了额外的开销。</li>
<li>使用 CUTLASS INT8 GeMM（通用矩阵乘）。适配 INT8 计算和 kernel
fuse。</li>
<li>Fusing Token-wise Activation Quantization。使用 kernel fuse 技术，将
Activation 的量化操作与之前的运算融合为一个运算，将反量化与 GeMM
融合为一个运算，由于融合的运算使用的是相同的数据，因此规避了量化/反量化带来的额外内存搬运开销。</li>
</ol>
<img src="/2024/05/15/ZeroQuant/f3.png" class="">
<h3 id="layer-by-layer-knowledge-distillation-lkd">Layer-by-layer
knowledge distillation (LKD)</h3>
<ol type="1">
<li>知识蒸馏可以有效降低量化导致的精度损失。</li>
<li>但是，知识蒸馏会极大增加内存和计算成本，而且往往需要原始训练数据（经常拿不到）。</li>
</ol>
<p>所以，paper 提出了逐层蒸馏技术。假设目标模型有 <span
class="math inline">\(N\)</span> 个 transformer 块 <span
class="math inline">\(L_1,L_2,\dots L_N\)</span>，数据集为 <span
class="math inline">\((X,Y)\)</span>，可以是原始训练数据，也可以来自其他地方。</p>
<p>LKD 使用未量化的模型作为教师模型。若 <span
class="math inline">\(L_k\)</span> 被量化，其量化后的版本为 <span
class="math inline">\(\hat{L_k}\)</span>。那么用 <span
class="math inline">\(L_{k-1}\)</span> 的输出来作为 <span
class="math inline">\(L_k,\hat{L_k}\)</span>的输入，度量学生模型和教师模型的差距，然后更新
<span class="math inline">\(L_k\)</span>。具体就像这个公式一样。</p>
<p><span
class="math display">\[\mathcal{L}_{LKD,k}=MSE(L_k(L_{k-1}(...L_1(X)...))-\hat{L_k}(L_{k-1}(...L_1(X)...)))\]</span></p>
<p>这么做带来了以下好处：</p>
<ol type="1">
<li>LKD 不需要额外的教师模型，而且学生和教师模型共享
L1-Lk-1，其运算结果在之前的迭代中以及知道了，所以额外的运算成本只有
Lk（类似动态规划）。</li>
<li>唯一需要 optimize 的层是 Lk，所以只要将 Lk 加载进内存。</li>
<li>LKD 是逐层优化的，并不优化端到端的模型，所以 LKD
不依赖于原始数据。</li>
</ol>
<h2 id="results">Results</h2>
<ul>
<li>ZeroQuant 可以将 BERT 和 类GPT-3 等模型的权重和激活精度降低到
INT8，对模型准确率的影响最小，同时，与 FP16
推理相比，这些模型的推理速度提高了 5.19 倍/4.16 倍；</li>
<li>ZeroQuant 加上 LKD 可将全连接模块中的权重量化为
INT4，以及注意力模块中的INT8权重和INT8激活，与FP16模型相比，内存占用减少了3倍；</li>
<li>ZeroQuant可以直接应用于GPT-J和GPT-NeoX等，其中我们的INT8模型达到了与FP16模型相似的精度，但效率提高了5.2倍。</li>
</ul>
<h2 id="reference">Reference</h2>
<ol type="1">
<li>ZeroQuant: Efficient and Affordable Post-Training Quantization for
Large-Scale Transformers, <span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvYWJzLzIyMDYuMDE4NjE=">https://arxiv.org/abs/2206.01861<i class="fa fa-external-link-alt"></i></span>.</li>
<li>ZeroQuant vedio&amp;slides, <span class="exturl" data-url="aHR0cHM6Ly9zbGlkZXNsaXZlLmNvbS8zODk5MTQ4NC96ZXJvcXVhbnQtZWZmaWNpZW50LWFuZC1hZmZvcmRhYmxlLXBvc3R0cmFpbmluZy1xdWFudGl6YXRpb24tZm9yLWxhcmdlc2NhbGUtdHJhbnNmb3JtZXJz">https://slideslive.com/38991484/zeroquant-efficient-and-affordable-posttraining-quantization-for-largescale-transformers<i class="fa fa-external-link-alt"></i></span>.</li>
<li>A Survey on Model Compression for Large Language Models, <span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvYWJzLzIzMDguMDc2MzM=">https://arxiv.org/abs/2308.07633<i class="fa fa-external-link-alt"></i></span>.</li>
<li>大模型压缩首篇综述来啦~, <span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC82NTI0MzQxNjU=">https://zhuanlan.zhihu.com/p/652434165<i class="fa fa-external-link-alt"></i></span>.</li>
<li>量化感知训练（Quantization-aware-training）探索-从原理到实践, <span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC81NDgxNzQ0MTY=">https://zhuanlan.zhihu.com/p/548174416<i class="fa fa-external-link-alt"></i></span>.</li>
<li>目前针对大模型进行量化的方法有哪些？, <span class="exturl" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3F1ZXN0aW9uLzYyNzQ4NDczMi9hbnN3ZXIvMzI2MTY3MTQ3OA==">https://www.zhihu.com/question/627484732/answer/3261671478<i class="fa fa-external-link-alt"></i></span>.</li>
<li>大模型量化技术原理-ZeroQuant系列, <span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC82ODM4MTM3Njk=">https://zhuanlan.zhihu.com/p/683813769<i class="fa fa-external-link-alt"></i></span></li>
</ol>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/MLSys/" rel="tag"># MLSys</a>
              <a href="/tags/LLM/" rel="tag"># LLM</a>
              <a href="/tags/LLM-Compression/" rel="tag"># LLM Compression</a>
              <a href="/tags/Quantization/" rel="tag"># Quantization</a>
              <a href="/tags/PTQ/" rel="tag"># PTQ</a>
          </div>

        
  <div class="social-like a2a_kit a2a_kit_size_32 a2a_default_style">
    <a class="a2a_dd" target="_blank" rel="noopener" href="https://www.addtoany.com/share"></a>
      <a class="a2a_button_facebook"></a>
      <a class="a2a_button_twitter"></a>
  </div>

          <div class="post-nav">
            <div class="post-nav-item">
            </div>
            <div class="post-nav-item">
                <a href="/2024/05/15/MuCache/" rel="next" title="MuCache">
                  MuCache <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    
  
  <div class="comments giscus-container">
  </div>
  
  
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">NovaPigeon</span>
  </div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
       本站访客数：  <span id="busuanzi_value_site_uv"></span> 人次
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        本站总访问量： <span id="busuanzi_value_site_pv"></span> 次
      </span>
    </span>
</div>
  <div class="powered-by">由 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & <span class="exturl" data-url="aHR0cHM6Ly90aGVtZS1uZXh0LmpzLm9yZw==">NexT.Gemini</span> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

  <span class="exturl github-corner" data-url="aHR0cHM6Ly9naXRodWIuY29tL05vdmFQaWdlb24=" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></span>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"https://cdnjs.cloudflare.com/ajax/libs/pdfobject/2.3.0/pdfobject.min.js","integrity":"sha256-JJZNsid68vnh3/zyj0lY9BN5ynxVX/12XgOa1TlaYN0="},"url":"/lib/pdf/web/viewer.html"}</script>
  <script src="/js/third-party/tags/pdf.js"></script>

  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.9.0/mermaid.min.js","integrity":"sha256-stuqcu2FrjYCXDOytWFA5SoUE/r3nkp6gTglzNSlavU="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>

  <script class="next-config" data-name="wavedrom" type="application/json">{"enable":true,"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/wavedrom/3.5.0/wavedrom.min.js","integrity":"sha256-INLAoJc6quTNfiMWkGZniYO2cxE8mHpddnLow1m6RFs="}}</script>
  <script class="next-config" data-name="wavedrom_skin" type="application/json">{"enable":true,"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/wavedrom/3.5.0/skins/default.js","integrity":"sha256-fduc/Zszk5ezWws2uInY/ALWVmIrmV6VTgXbsYSReFI="}}</script>
  <script src="/js/third-party/tags/wavedrom.js"></script>



  <script src="/js/third-party/addtoany.js"></script>

  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","single_dollars":true,"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


  <script src="https://cdnjs.cloudflare.com/ajax/libs/quicklink/2.3.0/quicklink.umd.js" integrity="sha256-yvJQOINiH9fWemHn0vCA5lsHWJaHs6/ZmO+1Ft04SvM=" crossorigin="anonymous"></script>
  <script class="next-config" data-name="quicklink" type="application/json">{"enable":true,"home":true,"archive":true,"delay":true,"timeout":3000,"priority":true,"url":"https://novapigeon.github.io/2024/05/15/ZeroQuant/"}</script>
  <script src="/js/third-party/quicklink.js"></script>
<script class="next-config" data-name="giscus" type="application/json">{"enable":true,"repo":"NovaPigeon/NovaPigeon.github.io","repo_id":"R_kgDOL7zRSg","category":"Announcements","category_id":"DIC_kwDOL7zRSs4CfX-L","mapping":"pathname","strict":0,"reactions_enabled":1,"emit_metadata":1,"theme":"light","lang":"zh-CN","crossorigin":"anonymous","input_position":"bottom","loading":"lazy"}</script>

<script>
document.addEventListener('page:loaded', () => {
  if (!CONFIG.page.comments) return;

  NexT.utils.loadComments('.giscus-container')
    .then(() => NexT.utils.getScript('https://giscus.app/client.js', {
      attributes: {
        async                   : true,
        crossOrigin             : 'anonymous',
        'data-repo'             : CONFIG.giscus.repo,
        'data-repo-id'          : CONFIG.giscus.repo_id,
        'data-category'         : CONFIG.giscus.category,
        'data-category-id'      : CONFIG.giscus.category_id,
        'data-mapping'          : CONFIG.giscus.mapping,
        'data-strict'           : CONFIG.giscus.strict,
        'data-reactions-enabled': CONFIG.giscus.reactions_enabled,
        'data-emit-metadata'    : CONFIG.giscus.emit_metadata,
        'data-theme'            : CONFIG.giscus.theme,
        'data-lang'             : CONFIG.giscus.lang,
        'data-input-position'   : CONFIG.giscus.input_position,
        'data-loading'          : CONFIG.giscus.loading
      },
      parentNode: document.querySelector('.giscus-container')
    }));
});
</script>

</body>
</html>
